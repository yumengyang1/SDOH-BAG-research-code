{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77b3b0-58ac-41f9-a109-9fab840e10ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 三模态数据已拼接完成！总样本量: 17162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 脑指标已标准化 (z-score)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15098\\AppData\\Local\\Temp\\ipykernel_13712\\2668626086.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_all[\"group_id\"] = df_all[\"src_subject_id\"].astype(str) + \"_\" + df_all[\"rel_family_id\"].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 训练集: 8602  测试集: 8560\n",
      "Fitting 10 folds for each of 27 candidates, totalling 270 fits\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#====================#\n",
    "# 1️⃣ 读取并拼接三模态\n",
    "#====================#\n",
    "file_paths = {\n",
    "    \"smri\": r\"D:\\!!yym\\!!!ABCD_data\\abcd-data-release-5.1_new\\5.1processing\\BrainAGE\\smri_data.csv\",\n",
    "    \"dm\":   r\"D:\\!!yym\\!!!ABCD_data\\abcd-data-release-5.1_new\\5.1processing\\BrainAGE\\dm_data.csv\",\n",
    "    \"rsfmri\": r\"D:\\!!yym\\!!!ABCD_data\\abcd-data-release-5.1_new\\5.1processing\\BrainAGE\\rsfmri_data.csv\"\n",
    "}\n",
    "\n",
    "data_dict = {}\n",
    "common_cols = [\"src_subject_id\", \"rel_family_id\", \"interview_age\", \"sex\", \"eventname\"]\n",
    "\n",
    "for modality, path in file_paths.items():\n",
    "    df = pd.read_csv(path, na_values=[\" \", \"NA\"])\n",
    "    # 非 ID 列转成数值\n",
    "    for col in df.columns:\n",
    "        if col != \"src_subject_id\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    # 给特征加上模态前缀，避免重名\n",
    "    feat_cols = [c for c in df.columns if c not in common_cols + [\"group_id\"]]\n",
    "    df.rename(columns={c: f\"{modality}_{c}\" for c in feat_cols}, inplace=True)\n",
    "    data_dict[modality] = df[common_cols + [f\"{modality}_{c}\" for c in feat_cols]]\n",
    "\n",
    "# 按公共列横向合并三份数据\n",
    "df_all = reduce(lambda left, right: pd.merge(left, right, on=common_cols, how=\"inner\"),\n",
    "                data_dict.values())\n",
    "print(\"✅ 三模态数据已拼接完成！总样本量:\", df_all.shape[0])\n",
    "\n",
    "#====================#\n",
    "# 2️⃣ Z-score 标准化脑指标\n",
    "#====================#\n",
    "brain_cols = [c for c in df_all.columns if c not in common_cols]\n",
    "scaler = StandardScaler()\n",
    "df_all[brain_cols] = scaler.fit_transform(df_all[brain_cols])\n",
    "print(\"✅ 脑指标已标准化 (z-score)\")\n",
    "\n",
    "#====================#\n",
    "# 3️⃣ 训练/测试集划分\n",
    "#====================#\n",
    "df_all[\"group_id\"] = df_all[\"src_subject_id\"].astype(str) + \"_\" + df_all[\"rel_family_id\"].astype(str)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "for train_idx, test_idx in gss.split(df_all, groups=df_all[\"group_id\"]):\n",
    "    train_df = df_all.iloc[train_idx].copy()\n",
    "    test_df  = df_all.iloc[test_idx].copy()\n",
    "\n",
    "train_df[\"age_group\"] = np.digitize(train_df[\"interview_age\"], np.arange(100, 200, 10))\n",
    "print(f\"✅ 训练集: {train_df.shape[0]}  测试集: {test_df.shape[0]}\")\n",
    "\n",
    "#====================#\n",
    "# 4️⃣ XGBoost 超参数搜索\n",
    "#====================#\n",
    "param_grid = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"n_estimators\": [500, 800, 1000]\n",
    "}\n",
    "\n",
    "features = [c for c in train_df.columns\n",
    "            if c not in [\"src_subject_id\",\"rel_family_id\",\"interview_age\",\n",
    "                         \"group_id\",\"sex\",\"age_group\",\"eventname\"]]\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[\"interview_age\"]\n",
    "age_group = train_df[\"age_group\"]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_model, param_grid,\n",
    "    cv=skf.split(X_train, age_group),\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"✅ 多模态最佳超参数:\", grid_search.best_params_)\n",
    "\n",
    "#====================#\n",
    "# 5️⃣ 10 折回归校正系数\n",
    "#====================#\n",
    "beta_0_list, beta_1_list, beta_2_list = [], [], []\n",
    "y_train_full = train_df[\"interview_age\"]\n",
    "sex_train = train_df[\"sex\"]\n",
    "\n",
    "for train_idx, val_idx in skf.split(X_train, np.digitize(y_train_full, np.arange(10, 100, 5))):\n",
    "    X_fold_val = X_train.iloc[val_idx]\n",
    "    y_fold_val = y_train_full.iloc[val_idx]\n",
    "    sex_fold_val = sex_train.iloc[val_idx]\n",
    "\n",
    "    y_pred_fold = best_model.predict(X_fold_val)\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(np.column_stack((y_fold_val, sex_fold_val)), y_pred_fold)\n",
    "\n",
    "    beta_0_list.append(reg.intercept_)\n",
    "    beta_1_list.append(reg.coef_[0])\n",
    "    beta_2_list.append(reg.coef_[1])\n",
    "\n",
    "beta_0_final = np.mean(beta_0_list)\n",
    "beta_1_final = np.mean(beta_1_list)\n",
    "beta_2_final = np.mean(beta_2_list)\n",
    "print(f\"✅ 最终校正参数: β0={beta_0_final:.4f}, β1={beta_1_final:.4f}, β2={beta_2_final:.4f}\")\n",
    "\n",
    "#====================#\n",
    "# 6️⃣ 测试集评估\n",
    "#====================#\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[\"interview_age\"]\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"✅ 测试集评估:\",\n",
    "      f\"MAE={mean_absolute_error(y_test, y_test_pred):.4f}, \",\n",
    "      f\"RMSE={np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}, \",\n",
    "      f\"R²={r2_score(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "#====================#\n",
    "# 7️⃣ 全体样本预测 & BAG\n",
    "#====================#\n",
    "features_all = features\n",
    "y_all_pred = best_model.predict(df_all[features_all])\n",
    "\n",
    "# 校正脑龄\n",
    "y_all_corrected = (y_all_pred - beta_0_final - beta_2_final * df_all[\"sex\"]) / beta_1_final\n",
    "corrected_bag = y_all_corrected - df_all[\"interview_age\"]\n",
    "\n",
    "bag_results = pd.DataFrame({\n",
    "    \"src_subject_id\": df_all[\"src_subject_id\"],\n",
    "    \"eventname\": df_all[\"eventname\"],\n",
    "    \"chronological_age\": df_all[\"interview_age\"],\n",
    "    \"corrected_age\": y_all_corrected,\n",
    "    \"corrected_bag\": corrected_bag\n",
    "})\n",
    "\n",
    "output_path = r\"D:\\!!yym\\!!!ABCD_data\\abcd-data-release-5.1_new\\5.1processing\\BrainAGE\\multimodal_corrected_bag(1).csv\"\n",
    "bag_results.to_csv(output_path, index=False)\n",
    "print(\"✅ 多模态整合后的校正 BAG 结果已保存:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c6f70-415c-43f1-b7a5-e1b13fde3e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 保存模型和关键数据\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "joblib.dump(train_df, \"train_df.pkl\")\n",
    "joblib.dump(test_df, \"test_df.pkl\")\n",
    "joblib.dump(features, \"features.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
